{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'openai' from 'c:\\\\Users\\\\user\\\\anaconda3\\\\envs\\\\tamela_tensorflow\\\\Lib\\\\site-packages\\\\openai\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "#openai = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embark on a grand adventure. He had heard whispers of a hidden treasure guarded by the fierce Owl King. With a heart full of determination, Benjamin gathered his friends: a clever rabbit and a wise tortoise. Together, they journeyed through enchanted forests, ready to face whatever challenges lay ahead.\n"
     ]
    }
   ],
   "source": [
    "prompt_system = \"You are a helpful assistant whose goal is to help write stories.\"\n",
    "\n",
    "prompt = '''Continue the following story. Write no more than 50 words.\n",
    "Once upon a time, in a world where animals could speak, a courageous mouse named Benjamin decided to'''\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Product Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indulge in the elegance of our limited-edition fountain pen, exquisitely handcrafted from rich rosewood and adorned with shimmering gold accents. Each pen is a masterpiece, offering a smooth, effortless writing experience. Elevate your stationery collection with this timeless instrument, designed for those who appreciate the art of writing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt_system = \"You are a helpful assistent whose goal is to write product descriptions.\"\n",
    "\n",
    "prompt = '''Write a captivating product description for a luxurious, handcrafted, \n",
    "limited-edition fountain pen made from rosewood and gold. Write no more than 50 words.'''\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zero-Shot Prompting: \n",
    "Zero-shot prompting is when a model is asked to produce output without\n",
    "examples demonstrating the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden rays dance in the sky,  \n",
      "Whispers of warmth as breezes sigh.  \n",
      "Fields adorned in blossoms bright,  \n",
      "Days stretch long, a sweet delight.  \n",
      "\n",
      "Laughter echoes, children play,  \n",
      "Waves crash down, the sun’s bouquet.  \n",
      "Fireflies twinkle in twilight's embrace,  \n",
      "Summer’s magic, a fleeting grace.  \n"
     ]
    }
   ],
   "source": [
    "prompt_system = \"You are a helpful assistant whose goal is to write short poems\"\n",
    "\n",
    "prompt = '''Write a short poem about summer'''\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-Context Learning And Few-Shot Prompting\n",
    "\n",
    "\n",
    "In-context learning is an approach where the model learns from examples or\n",
    "demonstrations in the prompt. Few-shot prompting, a subset of in-context\n",
    "learning, presents the model with a small set of relevant examples or\n",
    "demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden sunlit days,  \n",
      "Fields alive with blooms and play,  \n",
      "Children laugh and sway.  \n",
      "\n",
      "Whispers of the breeze,  \n",
      "Crisp ice cream and shady trees,  \n",
      "Time drifts like the seas.  \n"
     ]
    }
   ],
   "source": [
    "prompt_system = \"You are a helpful assistant whose goal is to write short poems\"\n",
    "\n",
    "prompt = '''Write a short poem about summer'''\n",
    "\n",
    "examples = {\n",
    "    \"nature\": '''Birdsong fill the air, \\nMountains high and valleys deep, \\nNature's music sweet.''',\n",
    "    \"winter\": '''Snow blankets the ground, \\nSilence is the only sound, \\nWinter's beauty found.'''\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": prompt.format(topic=\"nature\")},\n",
    "        {\"role\": \"assistant\", \"content\": examples[\"nature\"]},\n",
    "        {\"role\": \"user\", \"content\": prompt.format(topic=\"winter\")},\n",
    "        {\"role\": \"assistant\", \"content\": examples[\"winter\"]},\n",
    "        {\"role\": \"user\", \"content\": prompt.format(topic=\"summer\")}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-Shot Prompting Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colour: purple\n",
      "emotion:  Emotion: creativity\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
    "    {\"color\": \"blue\", \"emotion\": \"serinity\"},\n",
    "    {\"color\": \"green\", \"emotion\": \"tranquility\"}\n",
    "]\n",
    "\n",
    "example_formatter_template = '''\n",
    "color: {color}\n",
    "emotion: {emotion}\\n\n",
    "'''\n",
    "\n",
    "example_prompt =  PromptTemplate(\n",
    "    input_variables=[\"color\", \"emotion\"],\n",
    "    template=example_formatter_template\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix='''Here are some examples of colors and their emotions associated with them:\\n\\n''',\n",
    "    suffix='''\\n\\nNow given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:''',\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
    "\n",
    "# Run the LLMChain to get the AI-generated emotion associated with the input\n",
    "# color\n",
    "\n",
    "response = chain.run({})\n",
    "\n",
    "print(\"colour: purple\")\n",
    "print(\"emotion: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Role Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theme: interstellar travel\n",
      "year: 3030\n",
      "AI generated song title:  How about \"Galactic Odyssey: Echoes of 3030\"? This title captures the adventurous spirit of interstellar travel while hinting at the echoes of past journeys and experiences in the vastness of space.\n"
     ]
    }
   ],
   "source": [
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "# Initialize LLM\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "template = '''\n",
    "As a futureristic robot band conductor, I need you to help me with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"theme\", \"year\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "#llm = OpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Input data for the prompt\n",
    "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "# Create LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the LLMChain to get the AI-generated song title\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"theme: interstellar travel\")\n",
    "print(\"year: 3030\")\n",
    "print(\"AI generated song title: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: The famous scientist who developed the theory of general relativity is Albert Einstein.\n",
      "fact: Albert Einstein's theory of general relativity, published in 1915, revolutionized our understanding of gravity. It posits that gravity is not a force in the traditional sense but rather a curvature of spacetime caused by the presence of mass. According to this theory, massive objects like planets and stars warp the fabric of spacetime around them, causing other objects to follow curved paths, which we perceive as gravitational attraction. General relativity has been confirmed through various experiments and observations, including the bending of light around massive objects and the precise movements of planets. It has profound implications for cosmology, black holes, and our understanding of the universe's structure and evolution.\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Prompt 1\n",
    "template_questions = '''\n",
    "What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "propmt_question = PromptTemplate(\n",
    "    template=template_questions,\n",
    "    input_variables=[]\n",
    ")\n",
    "\n",
    "# Prompt 2\n",
    "template_facts = '''\n",
    "Provide a breif description of {scientist}'s theory of general reletivity\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "prompt_fact = PromptTemplate(\n",
    "    template=template_facts,\n",
    "    input_variables=[\"scientist\"]\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=propmt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_facts = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_facts = chain_facts.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"fact:\", response_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad Prompt Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me something about dogs.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = '''Tell me something about {topic}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt.format(topic=\"dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientist: The famous scientist who developed the theory of general relativity is Albert Einstein.\n",
      "facts: Albert Einstein's theory of general relativity, published in 1915, revolutionized our understanding of gravity. It posits that gravity is not a force in the traditional sense but rather a curvature of spacetime caused by the presence of mass. According to this theory, massive objects like planets and stars warp the fabric of spacetime around them, causing other objects to follow curved paths, which we perceive as gravitational attraction. General relativity has been confirmed through various experiments and observations, including the bending of light around massive objects and the precise movements of planets. It has profound implications for cosmology, black holes, and our understanding of the universe's structure and evolution.\n"
     ]
    }
   ],
   "source": [
    "# Initialize llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "template_question = '''\n",
    "What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "propmt_question = PromptTemplate(\n",
    "    template=template_question,\n",
    "    input_variables=[]\n",
    ")\n",
    "\n",
    "template_facts = '''\n",
    "Provide a breif description of {scientist}'s theory of general reletivity\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "prompt_facts = PromptTemplate(\n",
    "    input_variables=[\"scientist\"],\n",
    "    template=template_facts\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=propmt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_facts = LLMChain(llm=llm, prompt=prompt_facts)\n",
    "\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "response_facts = chain_facts.run(input_data)\n",
    "\n",
    "print(\"scientist:\", scientist)\n",
    "print(\"facts:\", response_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: jazz pop rock\n",
      "Fact: Jazz, pop, and rock are three distinct musical genres that each have their own unique characteristics and cultural significance. Jazz is often characterized by its improvisational nature and complex harmonies, allowing for individual expression and creativity. Pop music tends to focus on catchy melodies and widespread appeal, often reflecting contemporary trends and themes. Rock music is known for its strong rhythms and electric instrumentation, often conveying powerful emotions and messages. Each genre has evolved over time, influencing and intersecting with one another, contributing to the rich tapestry of modern music.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Prompt 1\n",
    "template_question = \"\"\"What are some musical genres?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question,\n",
    "input_variables=[])\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and\n",
    "{genre3} without giving any specific details.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"genre1\", \"genre2\",\n",
    "\"genre3\"],\n",
    "template=template_fact)\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "# Assign three hardcoded genres\n",
    "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "# Input data for the second prompt\n",
    "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\": genre3}\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "print(\"Genres:\", genre1, genre2, genre3)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips for Effective Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 128-129: truncated \\uXXXX escape (3021654095.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 26\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 128-129: truncated \\uXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's is the secrete to happiness?\",\n",
    "        \"answer\": \"\"\"Finding balance in life and learning to enjoy small moments.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"\"\"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template =\"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    template=example_template,\n",
    "    input_variables=[\"query\", \"answer\"]\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI life coach. The assistant provides insightful and practical advices to users' questions. Here are some examples:\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI:\"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create an LLM Chain for the few-shot prompt template\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for effective communication skills?\"\n",
    "\n",
    "# Run llm chain\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"user_query:\", user_query)\n",
    "print(\"AI response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 131-132: truncated \\uXXXX escape (3271814454.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 28\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 131-132: truncated \\uXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "examples = [\n",
    "\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"\"\"Finding balance in life and learning to enjoy the small moments.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"\"\"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "life coach. The assistant provides insightful and practical advice to the\n",
    "\\users' questions. Here are some examples:\n",
    "\"\"\"\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the few-shot prompt template\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "# Run the LLMChain for the user query\n",
    "response = chain.run({\"query\": user_query})\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tamela_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
